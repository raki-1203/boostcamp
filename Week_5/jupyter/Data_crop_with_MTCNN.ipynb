{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c67ad-a3b7-494a-bfa6-d46587a43bba",
   "metadata": {},
   "source": [
    "`!pip install -U albumentations==0.5.2`\n",
    "\n",
    "`!pip install timm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e2812-81c1-409d-907a-5af0050ad32a",
   "metadata": {},
   "source": [
    "`!pip install facenet_pytorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import albumentations\n",
    "import timm\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from pytz import timezone\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f23ce44-0b68-4d1e-9007-8ac6caf922d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# mtcnn 활용법 체크\n",
    "\n",
    "```python\n",
    "mtcnn = MTCNN(keep_all=True, device=cfg.device)\n",
    "\n",
    "idx = np.random.randint(0, 18900 / 7, 1)[0]\n",
    "img_path = glob.glob(cfg.img_dir + '/*/incorrect_*')[idx]\n",
    "img = np.array(Image.open(img_path))\n",
    "boxes, probs = mtcnn.detect(img)\n",
    "if isinstance(boxes, np.ndarray):\n",
    "    xmin = np.clip(int(boxes[0, 0]) - 50, 0, img.shape[0])\n",
    "    ymin = np.clip(int(boxes[0, 1]) - 50, 0, img.shape[1])\n",
    "    xmax = np.clip(int(boxes[0, 2]) + 50, 0, img.shape[0])\n",
    "    ymax = np.clip(int(boxes[0, 3]) + 50, 0, img.shape[1])\n",
    "\n",
    "    xmin, ymin, xmax, ymax\n",
    "    img = img[ymin:ymax, xmin:xmax, :]\n",
    "else:\n",
    "    # 직접 crop\n",
    "    img = img[100:400, 50:350, :]\n",
    "print(img.shape, probs)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "xmin = np.clip(int(boxes[0, 0]) - 30, 0, img.shape[0])\n",
    "ymin = np.clip(int(boxes[0, 1]) - 30, 0, img.shape[1])\n",
    "xmax = np.clip(int(boxes[0, 2]) + 30, 0, img.shape[0])\n",
    "ymax = np.clip(int(boxes[0, 3]) + 30, 0, img.shape[1])\n",
    "\n",
    "xmin, ymin, xmax, ymax\n",
    "img = img[ymin:ymax, xmin:xmax, :]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2462fd1-0b8f-450a-8e79-31a4531e9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "new_img_dir = '/opt/ml/input/data/train/new_imgs'\n",
    "img_path = '/opt/ml/input/data/train/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f0c27c-624b-4059-84a6-d729d053c902",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40fd6b6572147688a68b07a7c20d9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5401.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "18900\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for paths in tqdm(os.listdir(img_path)):\n",
    "    if paths[0] == '.':\n",
    "        continue\n",
    "    \n",
    "    sub_dir = os.path.join(img_path, paths)\n",
    "    \n",
    "    for imgs in os.listdir(sub_dir):\n",
    "        if imgs[0] == '.':\n",
    "            continue\n",
    "            \n",
    "        img_dir = os.path.join(sub_dir, imgs)\n",
    "        img = np.array(Image.open(img_dir))\n",
    "        \n",
    "        # mtcnn 적용\n",
    "        boxes, probs = mtcnn.detect(img)\n",
    "        \n",
    "        # boxes 확인\n",
    "        if not isinstance(boxes, np.ndarray):\n",
    "            # 직접 crop\n",
    "            img = img[100:400, 50:350, :]\n",
    "            cv2.resize(img, (224, 224))\n",
    "        # boxes size 확인\n",
    "        else:\n",
    "            xmin = int(boxes[0, 0])-30\n",
    "            ymin = int(boxes[0, 1])-30\n",
    "            xmax = int(boxes[0, 2])+30\n",
    "            ymax = int(boxes[0, 3])+30\n",
    "            \n",
    "            if xmin < 0: xmin = 0\n",
    "            if ymin < 0: ymin = 0\n",
    "            if xmax > 384: xmax = 384\n",
    "            if ymax > 512: ymax = 512\n",
    "            \n",
    "            img = img[ymin:ymax, xmin:xmax, :]\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            \n",
    "        tmp = os.path.join(new_img_dir, paths)\n",
    "        if not os.path.exists(tmp):\n",
    "            os.makedirs(tmp, exist_ok=True)\n",
    "        cnt += 1\n",
    "        plt.imsave(os.path.join(tmp, imgs.split('.')[0] + '.jpg'), img)\n",
    "        \n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a923ba-5ba2-4fd8-9277-82a161463f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_img_dir = '/opt/ml/input/data/eval/new_imgs'\n",
    "test_img_path = '/opt/ml/input/data/eval/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d6845d2-7832-4c77-bd45-dd4b67c3bb6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a076cbeac4e4d60b5d67fa9afde4456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25201.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12600\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for imgs in tqdm(os.listdir(test_img_path)):\n",
    "    if imgs[0] == '.':\n",
    "        continue\n",
    "        \n",
    "    img_dir = os.path.join(test_img_path, imgs)\n",
    "    img = np.array(Image.open(img_dir))\n",
    "        \n",
    "    # mtcnn 적용\n",
    "    boxes, probs = mtcnn.detect(img)\n",
    "\n",
    "    # boxes 확인\n",
    "    if not isinstance(boxes, np.ndarray):\n",
    "        # 직접 crop\n",
    "        img = img[100:400, 50:350, :]\n",
    "        cv2.resize(img, (224, 224))\n",
    "        \n",
    "    # boxes size 확인\n",
    "    else:\n",
    "        xmin = int(boxes[0, 0])-30\n",
    "        ymin = int(boxes[0, 1])-30\n",
    "        xmax = int(boxes[0, 2])+30\n",
    "        ymax = int(boxes[0, 3])+30\n",
    "\n",
    "        if xmin < 0: xmin = 0\n",
    "        if ymin < 0: ymin = 0\n",
    "        if xmax > 384: xmax = 384\n",
    "        if ymax > 512: ymax = 512\n",
    "\n",
    "        img = img[ymin:ymax, xmin:xmax, :]\n",
    "        cv2.resize(img, (224, 224))\n",
    "            \n",
    "    if not os.path.exists(new_test_img_dir):\n",
    "        os.makedirs(new_test_img_dir, exist_ok=True)\n",
    "    cnt += 1\n",
    "    plt.imsave(os.path.join(new_test_img_dir, imgs.split('.')[0] + '.jpg'), img)\n",
    "        \n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74896e17-c974-4717-8bc1-1507ef1c66a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fdce54-4728-4188-b570-9df7cd5c69e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
