{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import albumentations\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from pytz import timezone\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from pytorch_pretrained_vit import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793b7cf4-fd7a-485d-ab96-1ee4ea92f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a8dffd-109b-4756-a4ca-679e6f91dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version: {}'.format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee4ee1fc-c5fd-4009-b590-d1bf3a92ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "SEED = 2021\n",
    "# random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)  # type: ignore\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "built-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    train_dir = '/opt/ml/input/data/train'\n",
    "    img_dir = f'{train_dir}/images'\n",
    "    df_path = f'{train_dir}/train_with_label.csv'\n",
    "    \n",
    "    model_save_path = '/opt/ml/code/model'\n",
    "    sumission_save_path = '/opt/ml/code/submission'\n",
    "    \n",
    "    test_dir = '/opt/ml/input/data/eval'\n",
    "    submission_dir = f'{sumission_save_path}/{datetime.datetime.today().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d\")}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98cf1878-b551-4827-9311-e46640ac66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(cfg.submission_dir):\n",
    "    os.mkdir(cfg.submission_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdfb7e07-276d-44c6-9c52-90cc796117a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is using!\n"
     ]
    }
   ],
   "source": [
    "## HYPER PARAMETER 정의\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.001\n",
    "CLASS_NUM = 18\n",
    "IMAGE_SIZE = 384\n",
    "PATIENCE = 5\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device} is using!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72120758-fa63-4603-9aa7-575558925147",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Pretrained Model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a43250-f95e-4f5e-b2da-613bee424c1c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n",
      "네트워크 필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수 (예측 class type 개수) 1000\n",
      "ViT(\n",
      "  (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (positional_embedding): PositionalEmbedding1D()\n",
      "  (transformer): Transformer(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (6): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (7): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (8): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (9): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (10): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (11): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vit = ViT('B_16_imagenet1k', pretrained=True)\n",
    "print('네트워크 필요 입력 채널 개수', vit.patch_embedding.weight.shape[1])\n",
    "print('네트워크 출력 채널 개수 (예측 class type 개수)', vit.fc.weight.shape[0])\n",
    "print(vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df7e3ef-516f-4c21-9c12-1a8238a87832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네트워크 출력 채널 개수 (예측 class type 개수) 18\n"
     ]
    }
   ],
   "source": [
    "# target model의 출력 크기를 변경하여 줍니다.\n",
    "vit.fc = torch.nn.Linear(in_features=768, out_features=CLASS_NUM, bias=True)\n",
    "\n",
    "# 새롭게 넣은 네트워크 가중치를 xavier uniform으로 초기화\n",
    "torch.nn.init.xavier_uniform_(vit.fc.weight)\n",
    "stdv = 1.0/np.sqrt(768)\n",
    "vit.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "print('네트워크 출력 채널 개수 (예측 class type 개수)', vit.fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df5d21a3-d033-4ea4-825e-78be8291c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vit.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b59c62cb-aebb-4ed8-bb73-aed9feae5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vit.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be63323-9202-4f52-9ad2-4bee7abb8922",
   "metadata": {},
   "source": [
    "### requires_grad = False 적용 됐는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4817ad0-8d89-42c6-8858-d2a7153b4240",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 1.2565e-02,  5.0151e-02,  5.6412e-02,  ...,  9.1647e-02,\n",
       "            1.1258e-01,  1.2726e-01],\n",
       "          [ 1.2852e-02,  1.4875e-02,  2.2059e-02,  ...,  8.7276e-02,\n",
       "            4.2421e-02,  8.9284e-02],\n",
       "          [ 1.8606e-02,  1.3768e-02, -2.5441e-03,  ...,  7.8996e-02,\n",
       "            3.5360e-02,  3.8059e-02],\n",
       "          ...,\n",
       "          [-1.3499e-02, -3.9727e-03, -5.3725e-02,  ..., -5.8909e-02,\n",
       "           -6.8349e-02,  1.9621e-02],\n",
       "          [ 4.0168e-02, -4.4040e-02, -2.1628e-02,  ...,  1.2683e-02,\n",
       "           -3.8754e-02,  8.5574e-02],\n",
       "          [ 7.1434e-02,  8.2304e-02,  3.8617e-02,  ...,  1.0045e-01,\n",
       "            1.2122e-01,  1.6293e-01]],\n",
       "\n",
       "         [[-6.5743e-02, -4.0097e-02, -4.2712e-02,  ..., -6.1647e-02,\n",
       "           -2.6194e-02, -2.0021e-02],\n",
       "          [-6.5871e-03, -9.1357e-03, -5.8212e-03,  ..., -3.3783e-02,\n",
       "           -4.6455e-02, -2.4184e-03],\n",
       "          [ 4.9546e-02,  3.6097e-02,  1.6419e-02,  ..., -3.5878e-02,\n",
       "           -4.1035e-02, -3.4361e-02],\n",
       "          ...,\n",
       "          [ 3.7240e-02,  2.1497e-02, -5.8303e-02,  ..., -2.2255e-02,\n",
       "           -3.4222e-02,  4.2295e-02],\n",
       "          [ 5.9258e-02, -4.6368e-02, -5.7089e-02,  ...,  2.3233e-02,\n",
       "           -2.6052e-02,  8.5357e-02],\n",
       "          [ 3.1775e-02,  1.1274e-02, -5.4308e-02,  ...,  4.9525e-02,\n",
       "            7.4975e-02,  1.0780e-01]],\n",
       "\n",
       "         [[-1.2016e-01, -4.1527e-02,  1.5494e-03,  ..., -2.6646e-02,\n",
       "           -2.3138e-02, -4.8311e-02],\n",
       "          [-8.5549e-02, -1.9950e-02,  2.4795e-02,  ...,  2.8293e-02,\n",
       "           -9.7463e-03, -1.0840e-02],\n",
       "          [-5.5871e-02, -8.1742e-03,  1.6678e-03,  ...,  2.4132e-02,\n",
       "            4.0126e-05, -2.7243e-02],\n",
       "          ...,\n",
       "          [-3.1111e-02,  2.6241e-02,  6.8386e-03,  ..., -5.4414e-03,\n",
       "           -4.7069e-02, -2.5514e-02],\n",
       "          [-1.8338e-02, -7.0701e-02, -3.2805e-02,  ..., -1.3927e-02,\n",
       "           -9.2267e-02, -1.5203e-02],\n",
       "          [-6.3881e-02, -6.3226e-02, -1.1911e-01,  ..., -7.8771e-02,\n",
       "           -5.4966e-02, -3.2131e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.6794e-02,  2.1484e-02,  2.2694e-02,  ...,  9.6102e-03,\n",
       "           -3.5343e-02, -2.8779e-02],\n",
       "          [-4.3694e-02,  6.9707e-02,  8.6843e-02,  ...,  6.0555e-02,\n",
       "            7.2600e-02, -2.4046e-02],\n",
       "          [-7.1584e-02, -1.0286e-02,  2.3583e-02,  ...,  6.9430e-02,\n",
       "            6.5241e-02,  1.9255e-02],\n",
       "          ...,\n",
       "          [-1.0280e-01,  3.6752e-02,  1.4718e-01,  ...,  4.1795e-02,\n",
       "            2.5207e-02, -1.8981e-02],\n",
       "          [-1.1252e-01,  8.8516e-02,  6.0891e-02,  ...,  5.5676e-02,\n",
       "            6.3082e-02, -7.4723e-02],\n",
       "          [-9.2966e-02, -3.7557e-02,  9.0750e-05,  ...,  1.0870e-01,\n",
       "            1.0856e-02, -3.3545e-02]],\n",
       "\n",
       "         [[-1.4073e-02,  3.7215e-02,  2.2799e-02,  ...,  4.0167e-03,\n",
       "           -4.3878e-02, -2.9782e-02],\n",
       "          [-2.3619e-02,  7.6268e-02,  9.2468e-02,  ...,  7.0096e-03,\n",
       "            2.6469e-02, -5.8392e-02],\n",
       "          [-3.7431e-02,  1.5382e-02,  5.4178e-02,  ..., -2.1885e-03,\n",
       "           -8.6988e-03, -4.7930e-02],\n",
       "          ...,\n",
       "          [-1.1326e-01,  1.4799e-02,  1.1142e-01,  ...,  5.2114e-02,\n",
       "            4.2533e-02,  2.5318e-02],\n",
       "          [-9.9155e-02,  1.0201e-01,  7.4954e-02,  ...,  5.7208e-02,\n",
       "            7.5540e-02, -4.7929e-02],\n",
       "          [-5.7542e-02,  9.4806e-03,  5.5856e-02,  ...,  1.0918e-01,\n",
       "            1.6742e-02, -2.8114e-02]],\n",
       "\n",
       "         [[-1.5598e-02,  1.7224e-02, -1.8340e-02,  ...,  5.6132e-02,\n",
       "            3.5205e-02,  8.5018e-02],\n",
       "          [-4.0477e-02,  1.3300e-02, -4.3761e-03,  ...,  1.3904e-02,\n",
       "            3.9968e-02,  1.8654e-02],\n",
       "          [-6.7815e-02, -4.9325e-02, -3.3638e-02,  ...,  9.9312e-03,\n",
       "           -3.3900e-04,  1.0532e-02],\n",
       "          ...,\n",
       "          [-6.1373e-02,  1.3472e-02,  7.5450e-02,  ..., -3.8321e-02,\n",
       "           -6.2348e-04,  4.2782e-02],\n",
       "          [-5.4899e-02,  1.1967e-01,  6.1561e-02,  ..., -2.7963e-02,\n",
       "            3.3635e-02, -3.8119e-02],\n",
       "          [-4.3857e-02,  3.5235e-02,  8.0381e-02,  ...,  2.8755e-02,\n",
       "           -2.9105e-02, -4.1935e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.8654e-02, -2.7537e-03, -1.3501e-02,  ...,  1.8031e-03,\n",
       "            8.7084e-03,  2.6031e-03],\n",
       "          [ 1.1733e-02,  2.1421e-02,  3.1221e-03,  ..., -9.0747e-03,\n",
       "           -9.6422e-03, -1.8114e-02],\n",
       "          [ 9.8718e-03,  2.7302e-02,  9.7088e-03,  ..., -1.3766e-02,\n",
       "           -1.5553e-02, -2.6662e-02],\n",
       "          ...,\n",
       "          [ 1.9967e-02,  1.0951e-02,  5.4776e-03,  ..., -4.6278e-03,\n",
       "            1.2314e-03,  1.0615e-02],\n",
       "          [ 2.6403e-02,  7.7280e-03,  8.0880e-03,  ..., -4.0965e-03,\n",
       "            5.3065e-04,  2.3061e-02],\n",
       "          [ 7.5078e-03, -2.6551e-03, -1.6407e-02,  ..., -1.0824e-02,\n",
       "            8.4274e-03,  2.7700e-02]],\n",
       "\n",
       "         [[-1.5341e-02,  9.0329e-03,  4.9272e-03,  ...,  3.3444e-02,\n",
       "            4.4774e-02,  4.2661e-02],\n",
       "          [ 5.4720e-04,  2.1040e-02,  7.4403e-03,  ...,  1.2624e-02,\n",
       "            1.0271e-02,  6.8971e-03],\n",
       "          [-7.8813e-03,  2.3678e-02,  9.0275e-03,  ...,  4.0863e-04,\n",
       "            3.2395e-04, -1.0001e-02],\n",
       "          ...,\n",
       "          [ 2.7482e-03,  2.5414e-03,  2.7444e-03,  ..., -2.8938e-03,\n",
       "            1.0710e-03,  9.1542e-03],\n",
       "          [-1.3198e-03, -3.3861e-03, -3.8207e-04,  ..., -2.0378e-03,\n",
       "            1.1833e-03,  1.4114e-02],\n",
       "          [-2.8547e-02, -2.4505e-02, -2.6835e-02,  ..., -1.0802e-02,\n",
       "            3.7567e-03,  1.2127e-02]],\n",
       "\n",
       "         [[-4.2877e-02, -5.4672e-03, -1.1905e-02,  ..., -9.0198e-03,\n",
       "           -2.6898e-03, -9.6997e-03],\n",
       "          [-1.8597e-02,  1.5528e-02,  5.1666e-03,  ..., -3.5681e-03,\n",
       "           -8.8190e-03, -1.7987e-02],\n",
       "          [-2.2385e-02,  1.6882e-02,  9.4199e-03,  ...,  1.8204e-03,\n",
       "           -4.6610e-03, -2.2602e-02],\n",
       "          ...,\n",
       "          [ 9.8044e-03,  1.8803e-02,  1.8214e-02,  ...,  1.2698e-02,\n",
       "            8.0527e-03, -1.7251e-03],\n",
       "          [ 5.9487e-03,  1.5192e-02,  2.5436e-02,  ...,  1.1565e-02,\n",
       "            6.7154e-03,  4.1164e-03],\n",
       "          [-1.4226e-02,  3.5444e-03,  3.7645e-03,  ...,  5.8494e-03,\n",
       "            1.0576e-02,  3.9379e-03]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-4.2030e-02,  1.9028e-02,  6.4333e-02,  ..., -3.2733e-02,\n",
       "           -4.5133e-02, -1.1409e-03],\n",
       "          [-4.3942e-02,  2.6485e-02,  7.6391e-02,  ..., -4.2077e-02,\n",
       "           -4.3641e-02, -1.9605e-02],\n",
       "          [-2.6738e-02,  7.1210e-03,  7.3397e-02,  ..., -3.7186e-02,\n",
       "           -4.7684e-02, -3.6264e-02],\n",
       "          ...,\n",
       "          [ 6.1151e-03, -1.1410e-02,  1.6043e-02,  ...,  1.2978e-01,\n",
       "            5.1439e-02, -4.0075e-02],\n",
       "          [ 9.4656e-03,  2.1373e-02,  7.2300e-03,  ...,  5.2265e-02,\n",
       "            3.2481e-02, -5.5113e-02],\n",
       "          [ 2.6959e-02, -1.4840e-02, -1.2569e-02,  ..., -4.9514e-02,\n",
       "           -5.8585e-02, -7.2413e-02]],\n",
       "\n",
       "         [[-1.1787e-01, -4.4363e-02,  8.3170e-03,  ..., -1.0518e-01,\n",
       "           -1.2108e-01, -7.8600e-02],\n",
       "          [-9.6480e-02, -7.3148e-03,  5.5144e-02,  ..., -6.9812e-02,\n",
       "           -8.2914e-02, -6.7842e-02],\n",
       "          [-7.1035e-02, -1.3392e-02,  7.7101e-02,  ..., -2.9866e-02,\n",
       "           -5.5953e-02, -5.6992e-02],\n",
       "          ...,\n",
       "          [ 2.4078e-02,  8.2006e-03,  3.1317e-02,  ...,  1.8394e-01,\n",
       "            9.2883e-02, -1.5517e-02],\n",
       "          [ 2.8409e-02,  4.7666e-02,  2.6024e-02,  ...,  9.1113e-02,\n",
       "            6.5683e-02, -3.3845e-02],\n",
       "          [ 3.3218e-02,  1.2979e-03,  1.4505e-03,  ..., -2.6671e-02,\n",
       "           -3.8411e-02, -5.3128e-02]],\n",
       "\n",
       "         [[-7.1489e-02, -2.5643e-02, -4.4978e-03,  ..., -6.8421e-02,\n",
       "           -6.2288e-02, -2.4977e-02],\n",
       "          [-5.0993e-02, -8.7357e-04,  2.5055e-02,  ..., -5.6044e-02,\n",
       "           -4.9015e-02, -2.5564e-02],\n",
       "          [-3.8224e-02, -1.1370e-02,  3.8156e-02,  ..., -3.4455e-02,\n",
       "           -4.3276e-02, -2.6160e-02],\n",
       "          ...,\n",
       "          [ 2.6710e-03, -1.2844e-02, -3.6508e-03,  ...,  7.1426e-02,\n",
       "            3.0519e-02, -2.6537e-02],\n",
       "          [ 7.1142e-03,  2.8557e-02, -4.2449e-03,  ...,  2.7005e-02,\n",
       "            3.2269e-02, -2.8571e-02],\n",
       "          [ 1.3217e-02, -2.4167e-03, -1.4716e-04,  ..., -2.3195e-02,\n",
       "           -3.2860e-02, -4.3434e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 6.7506e-02,  8.4509e-02,  8.5287e-02,  ..., -3.2347e-03,\n",
       "            3.0445e-03, -4.5977e-02],\n",
       "          [-4.2884e-02, -4.4068e-02, -4.8058e-02,  ..., -7.2502e-02,\n",
       "           -7.5978e-02, -6.8845e-02],\n",
       "          [-6.9961e-02, -5.6970e-02, -6.3465e-02,  ..., -4.3159e-02,\n",
       "           -3.7520e-02, -6.8503e-02],\n",
       "          ...,\n",
       "          [ 1.9694e-02,  8.9486e-02,  3.5444e-02,  ...,  1.4467e-02,\n",
       "            5.0818e-02,  3.1521e-02],\n",
       "          [ 3.2380e-02,  2.7274e-02,  6.8423e-03,  ...,  7.1843e-02,\n",
       "            5.8751e-02,  6.9343e-02],\n",
       "          [-9.6560e-02, -7.2266e-02, -1.4903e-01,  ..., -3.4462e-03,\n",
       "            5.0017e-02,  2.6314e-02]],\n",
       "\n",
       "         [[ 8.6399e-02,  5.9598e-02,  3.7973e-02,  ..., -1.5695e-02,\n",
       "           -1.2110e-02, -7.2237e-02],\n",
       "          [-1.8027e-02, -6.6672e-02, -9.4532e-02,  ..., -1.0055e-01,\n",
       "           -9.7308e-02, -1.0100e-01],\n",
       "          [-3.2357e-02, -6.8884e-02, -1.0535e-01,  ..., -8.6404e-02,\n",
       "           -6.5733e-02, -1.0156e-01],\n",
       "          ...,\n",
       "          [ 6.2945e-02,  1.0931e-01,  5.0812e-02,  ...,  3.5208e-02,\n",
       "            5.4194e-02, -1.1297e-02],\n",
       "          [ 6.5731e-02,  2.7658e-02,  6.0188e-03,  ...,  9.3592e-02,\n",
       "            6.0386e-02,  2.7654e-02],\n",
       "          [-4.8257e-02, -6.1641e-02, -1.3993e-01,  ...,  2.1816e-02,\n",
       "            5.4900e-02,  4.6859e-03]],\n",
       "\n",
       "         [[ 6.4411e-02,  2.3024e-02,  1.3629e-02,  ..., -3.5099e-03,\n",
       "            2.7371e-03, -5.7100e-02],\n",
       "          [ 1.2269e-02, -3.6985e-02, -5.3953e-02,  ..., -3.1441e-02,\n",
       "           -2.9184e-02, -4.2272e-02],\n",
       "          [ 2.5164e-02, -2.2583e-02, -6.5218e-02,  ..., -1.8632e-02,\n",
       "            7.2691e-03, -3.3351e-02],\n",
       "          ...,\n",
       "          [ 5.8251e-02,  8.5817e-02,  4.3455e-02,  ..., -1.2170e-02,\n",
       "           -1.4801e-02, -9.3918e-02],\n",
       "          [ 8.8178e-02,  3.1812e-02,  3.9625e-02,  ...,  2.3183e-02,\n",
       "           -1.9345e-02, -5.2095e-02],\n",
       "          [ 5.5228e-02,  1.8218e-02, -4.2014e-02,  ..., -2.7958e-02,\n",
       "           -1.8038e-03, -4.5204e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.4138e-02, -1.6657e-03,  2.9560e-03,  ..., -5.5894e-03,\n",
       "           -4.7286e-03,  2.0084e-03],\n",
       "          [ 2.4601e-03, -5.4764e-03, -5.6577e-03,  ...,  3.7167e-03,\n",
       "           -5.0373e-03,  6.8264e-03],\n",
       "          [-5.6357e-03, -1.2495e-02, -5.8746e-03,  ...,  4.2828e-03,\n",
       "           -5.8635e-03,  2.2794e-03],\n",
       "          ...,\n",
       "          [-5.0720e-03, -4.4837e-03, -4.0962e-04,  ...,  5.5771e-04,\n",
       "           -6.6285e-03, -3.9882e-03],\n",
       "          [ 3.3248e-03, -1.7793e-03, -3.7289e-03,  ...,  1.6753e-03,\n",
       "            5.3423e-04,  4.7356e-05],\n",
       "          [-2.0546e-03, -9.9105e-03, -8.6719e-03,  ...,  8.2818e-03,\n",
       "            2.0287e-03, -2.6160e-03]],\n",
       "\n",
       "         [[ 9.1460e-03,  1.9795e-02,  2.1817e-02,  ...,  8.0892e-03,\n",
       "            1.0683e-02,  1.8909e-02],\n",
       "          [ 1.9685e-02,  8.6929e-03,  8.4845e-03,  ...,  1.1345e-02,\n",
       "            8.1196e-03,  1.8704e-02],\n",
       "          [ 7.6399e-03, -4.0746e-03,  1.7637e-03,  ...,  5.2651e-03,\n",
       "           -3.1755e-03,  5.3184e-03],\n",
       "          ...,\n",
       "          [ 3.2362e-03,  3.4557e-03,  2.0291e-03,  ..., -1.8053e-03,\n",
       "           -2.4599e-03,  4.9196e-03],\n",
       "          [ 1.6682e-02,  9.2470e-03,  6.9501e-03,  ...,  8.4090e-03,\n",
       "            9.3967e-03,  1.5295e-02],\n",
       "          [ 3.3823e-03,  3.9678e-04, -1.2765e-03,  ...,  1.0741e-02,\n",
       "            8.7188e-03,  7.7513e-03]],\n",
       "\n",
       "         [[-6.5223e-03, -2.2716e-04,  4.5419e-03,  ...,  4.3663e-03,\n",
       "           -4.4146e-03,  5.1815e-03],\n",
       "          [ 4.3692e-03, -9.4791e-03, -5.4873e-03,  ..., -6.1034e-04,\n",
       "           -1.0230e-02,  6.8884e-04],\n",
       "          [ 1.6400e-03, -8.0415e-03, -4.8580e-04,  ...,  5.6003e-04,\n",
       "           -9.9317e-03, -3.7330e-03],\n",
       "          ...,\n",
       "          [-5.6762e-03, -6.9360e-03,  1.1010e-03,  ...,  2.0443e-03,\n",
       "           -7.3749e-03, -4.5795e-04],\n",
       "          [-6.4955e-03, -1.3482e-02, -7.7439e-03,  ...,  6.1421e-04,\n",
       "           -7.8671e-03,  2.0326e-04],\n",
       "          [-1.6992e-02, -1.9719e-02, -1.4852e-02,  ...,  1.1237e-03,\n",
       "           -1.3371e-02, -7.2915e-03]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vit.patch_embedding.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2973859-79e1-4499-a0fb-b3056d846c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0871,  0.0813,  0.0376,  ..., -0.0113,  0.0165, -0.0697],\n",
       "        [-0.0657,  0.0575,  0.0863,  ...,  0.0762,  0.0082,  0.0395],\n",
       "        [ 0.0582, -0.0868, -0.0620,  ..., -0.0386,  0.0801,  0.0522],\n",
       "        ...,\n",
       "        [-0.0777,  0.0180,  0.0338,  ..., -0.0216,  0.0589, -0.0549],\n",
       "        [-0.0488,  0.0436, -0.0851,  ...,  0.0524, -0.0657,  0.0541],\n",
       "        [-0.0510, -0.0265,  0.0577,  ..., -0.0110, -0.0380, -0.0638]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vit.fc.parameters())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-channels",
   "metadata": {},
   "source": [
    "## 2. Train Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extensive-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.img_paths = df['image_path']\n",
    "        self.transform = transform\n",
    "        self.y = df['target']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.img_paths.iloc[idx]))\n",
    "        label = self.y.iloc[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)\n",
    "            image = image['image']\n",
    "        return image, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed8aff6b-4bf3-4be4-a0dd-03a101a5e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(cfg.train_dir, 'train_with_label.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f935da08-8895-4262-aaa8-129aafa61fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13230, 7), (5670, 7))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, valid_df = train_test_split(df, test_size=0.3, stratify=df['target'], \n",
    "                                      shuffle=True, random_state=2021)\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050172f0-02a6-4c9d-bca4-ef04e64ee270",
   "metadata": {},
   "source": [
    "# train_df 이미지의 pixel 값의 mean & std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a44b53-d5f9-481d-a47c-7360b0a958b5",
   "metadata": {},
   "source": [
    "images_info = {'height': [], 'width': [], 'means': [], 'stds': []}\n",
    "for i, image_path in enumerate(tqdm(train_df.image_path)):\n",
    "    img = np.array(Image.open(image_path))\n",
    "    h, w, _ = img.shape\n",
    "    images_info['height'].append(h)\n",
    "    images_info['width'].append(w)\n",
    "    images_info['means'].append(img.mean(axis=(0, 1)))\n",
    "    images_info['stds'].append(img.std(axis=(0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9468e83a-97c2-413d-babd-00b37d13a44d",
   "metadata": {},
   "source": [
    "print('Train Data')\n",
    "\n",
    "print(f'Minimum height for dataset is {np.min(images_info[\"height\"])}')\n",
    "print(f'Maximum height for dataset is {np.max(images_info[\"height\"])}')\n",
    "print(f'Average height for dataset is {int(np.mean(images_info[\"height\"]))}')\n",
    "print(f'Minimum width for dataset is {np.min(images_info[\"width\"])}')\n",
    "print(f'Maximum width for dataset is {np.max(images_info[\"width\"])}')\n",
    "print(f'Average width for dataset is {int(np.mean(images_info[\"width\"]))}')\n",
    "\n",
    "print(f'RGB Mean: {np.mean(images_info[\"means\"], axis=0) / 255.}')\n",
    "print(f'RGB Standard Deviation: {np.mean(images_info[\"stds\"], axis=0) / 255.}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00319887-1434-4a2b-9817-1fc0b8da1d54",
   "metadata": {},
   "source": [
    "`!pip install -U albumentations==0.5.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e7cd653-b5e1-4aa9-9fe1-e56f1ea7d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_list = [0.56074416, 0.52454219, 0.50188343]\n",
    "std_list = [0.23304677, 0.24291714, 0.24565602]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0928239c-354a-4412-9e89-a9efc08ae27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = albumentations.Compose([\n",
    "    albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.ShiftScaleRotate(p=0.5),\n",
    "    albumentations.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "    albumentations.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "    albumentations.GaussNoise(p=0.5),\n",
    "    albumentations.Normalize(mean=mean_list, std=std_list, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "valid_transform = albumentations.Compose([\n",
    "    albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    albumentations.Normalize(mean=mean_list, std=std_list, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e92a8f3-6d6d-418e-a295-c43adcc823bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13230, 5670)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = MyDataset(train_df, train_transform)\n",
    "valid_dataset = MyDataset(valid_df, valid_transform)\n",
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de510e9-e3b5-4131-963c-c720318c2fe6",
   "metadata": {},
   "source": [
    "## 3. Train DataLoader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "420c29dc-15aa-4aa5-95cb-a99926918517",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cedd39-f97e-49c1-8279-5725d0bf8e0a",
   "metadata": {},
   "source": [
    "## 4. Criterion & Optimizer & lr_scheduler & EarlyStopping 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e91324d6-68eb-482e-90da-2b5f955dece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_f1_score_max = -np.Inf\n",
    "\n",
    "    def __call__(self, val_f1_score, model):\n",
    "\n",
    "        score = val_f1_score\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1_score, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_f1_score, model):\n",
    "        '''Saves model when validation f1_score increase.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation f1_score increased ({self.val_f1_score_max:.6f} --> {val_f1_score:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), f'{os.path.join(cfg.model_save_path, \"VIT\")}/checkpoint.pt')\n",
    "        self.val_f1_score_max = val_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1481076-e8eb-4641-b55d-221402e7a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit.to(device)\n",
    "\n",
    "# weight = torch.tensor(len(train_df) // train_df.target.value_counts()).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "earlystop = EarlyStopping(patience=PATIENCE, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ecfc5b-203c-4f84-8323-e93e1f62e01f",
   "metadata": {},
   "source": [
    "## 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb416fb1-87f0-4545-8299-5cc9b36569a3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | loss : 1.7552 | F1_score : 52.1229: 100%|██████████| 133/133 [02:49<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0134, Accuracy : 0.5647, F1_score : 0.3965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | loss : 0.4646 | F1_score : 31.1935: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (-inf --> 0.554410).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0084, Accuracy : 0.7219, F1_score : 0.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | loss : 0.9944 | F1_score : 78.9918: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0077, Accuracy : 0.7527, F1_score : 0.5976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | loss : 0.3588 | F1_score : 34.9977: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.554410 --> 0.625091).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0064, Accuracy : 0.7890, F1_score : 0.6251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | loss : 0.8169 | F1_score : 87.9329: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0063, Accuracy : 0.7987, F1_score : 0.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | loss : 0.3266 | F1_score : 36.2787: 100%|██████████| 57/57 [01:07<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.625091 --> 0.648840).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0059, Accuracy : 0.8088, F1_score : 0.6488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | loss : 0.7411 | F1_score : 90.9676: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0057, Accuracy : 0.8140, F1_score : 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | loss : 0.2926 | F1_score : 38.8923: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.648840 --> 0.694572).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0053, Accuracy : 0.8263, F1_score : 0.6946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | loss : 0.6958 | F1_score : 93.5778: 100%|██████████| 133/133 [02:49<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0054, Accuracy : 0.8203, F1_score : 0.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | loss : 0.2852 | F1_score : 38.2954: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Validation Loss : 0.0051, Accuracy : 0.8245, F1_score : 0.6842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | loss : 0.6417 | F1_score : 94.7303: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0050, Accuracy : 0.8350, F1_score : 0.7166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | loss : 0.2692 | F1_score : 38.4003: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "Validation Loss : 0.0049, Accuracy : 0.8319, F1_score : 0.6822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | loss : 0.6200 | F1_score : 96.9841: 100%|██████████| 133/133 [02:48<00:00,  1.26s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0049, Accuracy : 0.8412, F1_score : 0.7339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | loss : 0.2604 | F1_score : 38.9921: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.694572 --> 0.699812).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0046, Accuracy : 0.8345, F1_score : 0.6998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | loss : 0.5811 | F1_score : 100.2067: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0045, Accuracy : 0.8526, F1_score : 0.7593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | loss : 0.2502 | F1_score : 39.1528: 100%|██████████| 57/57 [01:08<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.699812 --> 0.700745).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0045, Accuracy : 0.8419, F1_score : 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | loss : 0.5831 | F1_score : 99.1084: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0045, Accuracy : 0.8538, F1_score : 0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | loss : 0.2505 | F1_score : 39.0250: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Validation Loss : 0.0045, Accuracy : 0.8412, F1_score : 0.6961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | loss : 0.5703 | F1_score : 99.4705: 100%|██████████| 133/133 [02:48<00:00,  1.26s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0044, Accuracy : 0.8554, F1_score : 0.7536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | loss : 0.2484 | F1_score : 39.1079: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "Validation Loss : 0.0045, Accuracy : 0.8406, F1_score : 0.6964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | loss : 0.5806 | F1_score : 99.0381: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0045, Accuracy : 0.8531, F1_score : 0.7510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | loss : 0.2452 | F1_score : 39.3474: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.700745 --> 0.700801).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0045, Accuracy : 0.8435, F1_score : 0.7008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | loss : 0.5689 | F1_score : 100.0183: 100%|██████████| 133/133 [02:48<00:00,  1.26s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0044, Accuracy : 0.8579, F1_score : 0.7592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | loss : 0.2464 | F1_score : 38.5133: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8431, F1_score : 0.6895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | loss : 0.5602 | F1_score : 99.2823: 100%|██████████| 133/133 [02:48<00:00,  1.26s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8567, F1_score : 0.7524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | loss : 0.2457 | F1_score : 38.9835: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8427, F1_score : 0.6977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | loss : 0.5654 | F1_score : 99.8861: 100%|██████████| 133/133 [02:47<00:00,  1.26s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0044, Accuracy : 0.8531, F1_score : 0.7573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | loss : 0.2438 | F1_score : 39.3470: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.700801 --> 0.705229).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0044, Accuracy : 0.8468, F1_score : 0.7052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | loss : 0.5601 | F1_score : 99.9362: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8577, F1_score : 0.7574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | loss : 0.2434 | F1_score : 39.1012: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8452, F1_score : 0.6992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | loss : 0.5639 | F1_score : 100.1781: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8557, F1_score : 0.7593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | loss : 0.2448 | F1_score : 39.4777: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.705229 --> 0.705884).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0044, Accuracy : 0.8451, F1_score : 0.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | loss : 0.5617 | F1_score : 100.5865: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8578, F1_score : 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | loss : 0.2436 | F1_score : 38.8625: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8452, F1_score : 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | loss : 0.5609 | F1_score : 100.6124: 100%|██████████| 133/133 [02:48<00:00,  1.26s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8580, F1_score : 0.7634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | loss : 0.2445 | F1_score : 39.0279: 100%|██████████| 57/57 [01:07<00:00,  1.19s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8453, F1_score : 0.6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | loss : 0.5567 | F1_score : 100.1400: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8553, F1_score : 0.7582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | loss : 0.2433 | F1_score : 39.8908: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.705884 --> 0.709232).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0044, Accuracy : 0.8452, F1_score : 0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | loss : 0.5589 | F1_score : 100.6183: 100%|██████████| 133/133 [02:49<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8585, F1_score : 0.7629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | loss : 0.2434 | F1_score : 39.0522: 100%|██████████| 57/57 [01:08<00:00,  1.19s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8460, F1_score : 0.6980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | loss : 0.5612 | F1_score : 99.7499: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8558, F1_score : 0.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | loss : 0.2429 | F1_score : 39.2694: 100%|██████████| 57/57 [01:07<00:00,  1.19s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8453, F1_score : 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | loss : 0.5597 | F1_score : 99.9855: 100%|██████████| 133/133 [02:49<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8551, F1_score : 0.7571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | loss : 0.2434 | F1_score : 39.6484: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.709232 --> 0.709820).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0044, Accuracy : 0.8455, F1_score : 0.7098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | loss : 0.5564 | F1_score : 100.9978: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0042, Accuracy : 0.8594, F1_score : 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | loss : 0.2426 | F1_score : 39.8115: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score increased (0.709820 --> 0.710353).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.0044, Accuracy : 0.8451, F1_score : 0.7104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | loss : 0.5529 | F1_score : 102.1019: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8607, F1_score : 0.7725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | loss : 0.2436 | F1_score : 39.4731: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8455, F1_score : 0.7040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | loss : 0.5695 | F1_score : 100.0440: 100%|██████████| 133/133 [02:48<00:00,  1.26s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0044, Accuracy : 0.8534, F1_score : 0.7574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | loss : 0.2442 | F1_score : 38.9466: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8458, F1_score : 0.6988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | loss : 0.5642 | F1_score : 99.6678: 100%|██████████| 133/133 [02:48<00:00,  1.27s/it]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0043, Accuracy : 0.8517, F1_score : 0.7546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | loss : 0.2423 | F1_score : 39.6726: 100%|██████████| 57/57 [01:08<00:00,  1.20s/it]\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 7\n",
      "Validation Loss : 0.0044, Accuracy : 0.8450, F1_score : 0.7064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | loss : 0.4275 | F1_score : 74.2567:  74%|███████▎  | 98/133 [02:06<00:45,  1.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-08a9a50e2061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mtrain_running_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtrain_running_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         train_running_epoch_f1 += f1_score(preds.cpu().numpy(), \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "val_acc_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # Train phase\n",
    "    model.train()\n",
    "    \n",
    "    train_running_loss = 0\n",
    "    train_running_acc = 0\n",
    "    train_running_epoch_f1 = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader)\n",
    "    for X_batch, y_batch in pbar:\n",
    "        pbar.set_description(f'Epoch {epoch}/{EPOCHS} | loss : {train_running_loss:.4f} | F1_score : {train_running_epoch_f1:.4f}')\n",
    "        \n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).type(torch.cuda.LongTensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model.forward(X_batch)\n",
    "        _, preds = torch.max(y_pred, 1)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_running_loss += loss.item() / len(y_batch)\n",
    "        train_running_acc += torch.sum(preds == y_batch.data) / len(y_batch)\n",
    "        train_running_epoch_f1 += f1_score(preds.cpu().numpy(), \n",
    "                                           y_batch.cpu().numpy(), average='macro')\n",
    "        \n",
    "    exp_lr_scheduler.step()\n",
    "    \n",
    "    train_epoch_loss = train_running_loss / len(train_loader)\n",
    "    train_epoch_acc = train_running_acc / len(train_loader)\n",
    "    train_epoch_f1 = train_running_epoch_f1 / len(train_loader)\n",
    "    \n",
    "    train_acc_history.append(train_epoch_acc)\n",
    "    train_loss_history.append(train_epoch_loss)\n",
    "    \n",
    "    print(f'Train Loss : {train_epoch_loss:.4f}, Accuracy : {train_epoch_acc:.4f}, F1_score : {train_epoch_f1:.4f}')\n",
    "    \n",
    "    # Validation pahse\n",
    "    model.eval()\n",
    "    \n",
    "    valid_running_loss = 0\n",
    "    valid_running_acc = 0\n",
    "    valid_running_epoch_f1 = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(valid_loader)\n",
    "        for X_batch, y_batch in pbar:\n",
    "            pbar.set_description(f'Epoch {epoch}/{EPOCHS} | loss : {valid_running_loss:.4f} | F1_score : {valid_running_epoch_f1:.4f}')\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            y_pred = model.forward(X_batch)\n",
    "            _, preds = torch.max(y_pred, 1)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            \n",
    "            valid_running_loss += loss.item() / len(y_batch)\n",
    "            valid_running_acc += torch.sum(preds == y_batch.data) / len(y_batch)\n",
    "            valid_running_epoch_f1 += f1_score(preds.cpu().numpy(), \n",
    "                                           y_batch.cpu().numpy(), average='macro')\n",
    "            \n",
    "    valid_epoch_loss = valid_running_loss / len(valid_loader)\n",
    "    valid_epoch_acc = valid_running_acc / len(valid_loader)\n",
    "    valid_epoch_f1 = valid_running_epoch_f1 / len(valid_loader)\n",
    "    \n",
    "    earlystop(valid_epoch_f1, model)\n",
    "    \n",
    "    print(f'Validation Loss : {valid_epoch_loss:.4f}, Accuracy : {valid_epoch_acc:.4f}, F1_score : {valid_epoch_f1:.4f}')   \n",
    "    \n",
    "    if valid_epoch_f1 > best_f1:\n",
    "        best_f1 = valid_epoch_f1\n",
    "    \n",
    "    val_acc_history.append(valid_epoch_acc)\n",
    "    val_loss_history.append(valid_epoch_loss)\n",
    "    \n",
    "    if earlystop.early_stop:\n",
    "        print('Early stopping')\n",
    "        model.load_state_dict(torch.load(f'{os.path.join(cfg.model_save_path, \"VIT\")}/checkpoint.pt'))\n",
    "        break\n",
    "\n",
    "print('Best Validation F1_score: {:.4f}'.format(best_f1))\n",
    "torch.save(model.state_dict(),\n",
    "           f'{os.path.join(cfg.model_save_path, \"VIT\")}/best_model_{best_f1:.4f}.pt')\n",
    "print('학습 종료!')\n",
    "end = time.time()\n",
    "print(f'학습 총 걸린 시간 : {end - start:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f95aac6-3887-4371-a7d6-bbc095585e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].plot(train_acc_history, label='train_acc')\n",
    "axes[0].plot(val_acc_history, label='val_acc')\n",
    "axes[1].plot(train_loss_history, label='train_loss')\n",
    "axes[1].plot(val_loss_history, label='val_loss')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-feelings",
   "metadata": {},
   "source": [
    "## 6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d4130-6e04-4654-88e0-1fde6ef38d29",
   "metadata": {},
   "source": [
    "## 6.1 Test Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acffdc4d-4bd5-4244-baa6-d4c56e66320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = np.array(Image.open(self.img_paths[index]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)\n",
    "            image = image['image']\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "coral-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [02:29<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(cfg.test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(cfg.test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "dataset = TestDataset(image_paths, valid_transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "best_model_path = [file for file in glob.glob(os.path.join(cfg.model_save_path, 'VIT/*')) \n",
    "                   if 'checkpoint' in file][0]\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(cfg.submission_dir, 'submission_{}.csv'.format(\n",
    "    datetime.datetime.today().astimezone(timezone(\"Asia/Seoul\")).strftime('%Y-%m-%d_%H:%M:%S'))), \n",
    "                  index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4aa526a0-6da3-4e81-bf3b-0d216a3e1ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/ml/code/submission'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.sumission_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fbc4fe7-c5eb-4f13-81f0-97861e517437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f21725f5040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "cfg.sumission_save_pathtimm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "verbal-sample",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_384',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50_224_in21k',\n",
       " 'vit_base_resnet50_384',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vit_models = timm.list_models('*vit*')\n",
    "all_vit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d433962-df60-4245-9ff5-ebebfe6abdda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
