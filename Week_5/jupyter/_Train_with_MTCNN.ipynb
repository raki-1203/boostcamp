{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c67ad-a3b7-494a-bfa6-d46587a43bba",
   "metadata": {},
   "source": [
    "`!pip install -U albumentations==0.5.2`\n",
    "\n",
    "`!pip install timm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e2812-81c1-409d-907a-5af0050ad32a",
   "metadata": {},
   "source": [
    "`!pip install facenet_pytorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import albumentations\n",
    "import timm\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from pytz import timezone\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f23ce44-0b68-4d1e-9007-8ac6caf922d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# mtcnn 활용법 체크\n",
    "\n",
    "```python\n",
    "mtcnn = MTCNN(keep_all=True, device=cfg.device)\n",
    "\n",
    "idx = np.random.randint(0, 18900 / 7, 1)[0]\n",
    "img_path = glob.glob(cfg.img_dir + '/*/incorrect_*')[idx]\n",
    "img = np.array(Image.open(img_path))\n",
    "boxes, probs = mtcnn.detect(img)\n",
    "if isinstance(boxes, np.ndarray):\n",
    "    xmin = np.clip(int(boxes[0, 0]) - 50, 0, img.shape[0])\n",
    "    ymin = np.clip(int(boxes[0, 1]) - 50, 0, img.shape[1])\n",
    "    xmax = np.clip(int(boxes[0, 2]) + 50, 0, img.shape[0])\n",
    "    ymax = np.clip(int(boxes[0, 3]) + 50, 0, img.shape[1])\n",
    "\n",
    "    xmin, ymin, xmax, ymax\n",
    "    img = img[ymin:ymax, xmin:xmax, :]\n",
    "else:\n",
    "    # 직접 crop\n",
    "    img = img[100:400, 50:350, :]\n",
    "print(img.shape, probs)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "xmin = np.clip(int(boxes[0, 0]) - 30, 0, img.shape[0])\n",
    "ymin = np.clip(int(boxes[0, 1]) - 30, 0, img.shape[1])\n",
    "xmax = np.clip(int(boxes[0, 2]) + 30, 0, img.shape[0])\n",
    "ymax = np.clip(int(boxes[0, 3]) + 30, 0, img.shape[1])\n",
    "\n",
    "xmin, ymin, xmax, ymax\n",
    "img = img[ymin:ymax, xmin:xmax, :]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e7c6df-c8ee-45f6-bcce-310731165a6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e659b267-72c7-4244-8e1a-33fa55e0a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'train_dir': '/opt/ml/input/data/train',\n",
    "    'df_path': '/opt/ml/input/data/train/train_with_label.csv',\n",
    "    'model_save_path': '/opt/ml/code/model',\n",
    "    'submission_save_path': '/opt/ml/code/submission',\n",
    "    'test_dir': '/opt/ml/input/data/eval',\n",
    "    'submission_dir': '/opt/ml/code/submission/{}'.format(\n",
    "        datetime.datetime.today().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d\")),\n",
    "    'random_seed': 911203,\n",
    "    'epochs': 20,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.0001,\n",
    "    'class_num': 18,\n",
    "    'image_size': 224,\n",
    "    'num_workers': 4,\n",
    "    'device': torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "    'model_name': 'efficientnet_b4',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2cf8731-af8a-4e67-a4d0-502ed3697a3c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eca_efficientnet_b0',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b2a',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b3a',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_s',\n",
       " 'gc_efficientnet_b0',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 부를 수 있는 모델 확인\n",
    "all_models = timm.list_models('*efficient*')\n",
    "all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d31d4-fd56-44bd-80b5-c47ab2be3fb9",
   "metadata": {},
   "source": [
    "## RANDOM SEED 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f222122-342e-425e-9afd-cb68906499fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(SEED):\n",
    "    # Set random seed\n",
    "    # random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72120758-fa63-4603-9aa7-575558925147",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pretrained Model Class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c40c7eb-191f-49b3-9b91-428dfaedfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgClassifier(nn.Module):\n",
    "    def __init__(self, model_name, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a647712-d88b-4c4f-863d-296b621acbeb",
   "metadata": {},
   "source": [
    "## Fine Tuning & Feature extractor 설정 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db3c7c7a-8923-47f1-9c73-5a040006e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_train_mode(model, mode=0):\n",
    "    # Fine Tuning\n",
    "    if mode == 0:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    # Feature extractor\n",
    "    elif mode == 1:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        raise Exception('mode를 0: Fine Tuning 1: Feature extractor 를 위한 parameter를 넣으세요!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7fabc38c-d903-4842-b1dc-c8f8e2c506f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_make_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf4caf12-b4ec-440c-ad8f-1a0ace6124f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 Augmentation 을 위한 transform 정의 (albumentations 사용)\n",
    "transforms_dict = {\n",
    "    'train': albumentations.Compose([\n",
    "        albumentations.Resize(config['image_size'], config['image_size'], p=1.0),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.ShiftScaleRotate(rotate_limit=30, p=0.5),\n",
    "        albumentations.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        albumentations.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        albumentations.GaussNoise(p=0.5),\n",
    "        albumentations.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ]),\n",
    "    'valid': albumentations.Compose([\n",
    "        albumentations.Resize(config['image_size'], config['image_size'], p=1.0),\n",
    "        albumentations.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ]),\n",
    "    'test': albumentations.Compose([\n",
    "        albumentations.Resize(config['image_size'], config['image_size'], p=1.0),\n",
    "        albumentations.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7546cd-a96f-4e76-9cfd-dfb426c6bb8f",
   "metadata": {},
   "source": [
    "## Dataset Class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "076fc3dc-f28d-4a95-9b23-ffd5b43c8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, df, transform, mtcnn):\n",
    "        self.img_paths = df['image_path']\n",
    "        self.transform = transform\n",
    "        self.y = df['target']\n",
    "        self.mtcnn = mtcnn\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.img_paths.iloc[idx]))\n",
    "#         image = self.face_crop(image)\n",
    "        label = self.y.iloc[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)\n",
    "            image = image['image']\n",
    "        return image, torch.tensor(label)\n",
    "    \n",
    "    def face_crop(self, img):\n",
    "        boxes, probs = self.mtcnn.detect(img)\n",
    "        if isinstance(boxes, np.ndarray):\n",
    "            xmin = np.clip(int(boxes[0, 0]) - 50, 0, img.shape[0])\n",
    "            ymin = np.clip(int(boxes[0, 1]) - 50, 0, img.shape[1])\n",
    "            xmax = np.clip(int(boxes[0, 2]) + 50, 0, img.shape[0])\n",
    "            ymax = np.clip(int(boxes[0, 3]) + 50, 0, img.shape[1])\n",
    "\n",
    "            xmin, ymin, xmax, ymax\n",
    "            img = img[ymin:ymax, xmin:xmax, :]\n",
    "        else:\n",
    "            # 직접 crop\n",
    "            img = img[100:400, 50:350, :]\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5165bcc-52de-4dbe-9cb3-d071ffac074b",
   "metadata": {},
   "source": [
    "## EarlyStopping Class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "013a5ac2-cf03-4bc7-a7ae-3011ebaf4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingF1:\n",
    "    \"\"\"Early stops the training if validation f1-score doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, config, patience=5, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation f1-score improved.\n",
    "                            Default: 5\n",
    "            verbose (bool): If True, prints a message for each validation f1-score improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_f1_min = 0.0\n",
    "        self.config = config\n",
    "\n",
    "    def __call__(self, val_f1, model):\n",
    "\n",
    "        score = val_f1\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_f1, model):\n",
    "        '''Saves model when validation f1-score increase.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation f1-score increased ({self.val_f1_min:.6f} --> {val_f1:.6f}).  Saving model ...')\n",
    "        path = '{}'.format(os.path.join(self.config['model_save_path'], self.config['model_name']))\n",
    "        my_make_dir(path)\n",
    "        torch.save(model.state_dict(), '{}/checkpoint.pt'.format(path))\n",
    "        self.val_f1_min = val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fc18adc-174a-4334-8a02-964849cf5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    start = time.time()\n",
    "    \n",
    "    df = pd.read_csv(config['df_path'])\n",
    "\n",
    "    # 5개의 KFold\n",
    "    folds = StratifiedKFold(n_splits=5, \n",
    "                            shuffle=True, \n",
    "                            random_state=config['random_seed'])\n",
    "    folds = folds.split(np.arange(len(df)), df['target'].values)\n",
    "\n",
    "    train_idx, valid_idx = next(iter(folds))\n",
    "\n",
    "    print(len(train_idx), len(valid_idx))\n",
    "    \n",
    "    model = ImgClassifier(model_name=config['model_name'], n_class=config['class_num'], pretrained=True)\n",
    "    set_model_train_mode(model, 0)  # fine-tuning 방법 사용\n",
    "    model = model.to(config['device'])\n",
    "\n",
    "    mtcnn = MTCNN(keep_all=True, device=config['device'])\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    earlystop = EarlyStoppingF1(config, patience=3, verbose=True)\n",
    "    \n",
    "    df_dict = {\n",
    "        'train': df.iloc[train_idx].reset_index(drop=True),\n",
    "        'valid': df.iloc[valid_idx].reset_index(drop=True),\n",
    "    }\n",
    "\n",
    "    datasets_dict = {\n",
    "        tv: MaskDataset(df_dict[tv], transforms_dict[tv], mtcnn)\n",
    "        for tv in ['train', 'valid']\n",
    "    }\n",
    "\n",
    "    dataloader_dict = {\n",
    "        tv: torch.utils.data.DataLoader(\n",
    "            datasets_dict[tv],\n",
    "            batch_size=config['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=config['num_workers'],\n",
    "        )\n",
    "        for tv in ['train', 'valid']\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        tv: len(datasets_dict[tv]) \n",
    "        for tv in ['train', 'valid']\n",
    "    }\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    \n",
    "#     wandb.init(project='mask-image-classification', entity='raki-1203')\n",
    "    \n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        print(f'Epoch {epoch:02}/{config[\"epochs\"]}')\n",
    "        print('*' * 10)\n",
    "        \n",
    "        # 각 에폭(epoch)은 학습 단계와 검증 단계를 가짐\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 모델을 학습 모드로 설정\n",
    "            else:\n",
    "                model.eval()  # 모델을 평가 모드로 설정\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_f1 = 0.0\n",
    "            \n",
    "            # 데이터를 반복\n",
    "            pbar = tqdm(dataloader_dict[phase], total=len(dataloader_dict[phase]))\n",
    "            for inputs, labels in dataloader_dict[phase]:\n",
    "                pbar.set_description(f'''\n",
    "                    Epoch {epoch} | loss : {running_loss:.4f} | \n",
    "                    correct : {running_corrects :05} / {dataset_sizes[phase]} | F1_score : {running_f1:.4f}\n",
    "                ''')\n",
    "                inputs = inputs.to(config['device'])\n",
    "                labels = labels.to(config['device'])\n",
    "                \n",
    "                # 매개변수 경사도를 0으로 설정\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 순전파\n",
    "                # 학습 시에만 연산 기록을 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, dim=-1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # 학습 단계인 경우 역전파 + 최적화\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                # 통계\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                running_f1 += f1_score(preds.cpu().numpy(), \n",
    "                                       labels.cpu().numpy(), average='macro') * inputs.size(0)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            epoch_f1 = running_f1 / dataset_sizes[phase]\n",
    "            \n",
    "            print(f'{phase} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | F1-score: {epoch_f1:.4f}')\n",
    "\n",
    "            # Best f1-score 저장 및 early stopping 에서 모델 저장\n",
    "            if phase == 'valid':\n",
    "                if best_f1 < epoch_f1:\n",
    "                    best_f1 = epoch_f1\n",
    "                \n",
    "                earlystop(epoch_f1, model)\n",
    "                \n",
    "                if earlystop.early_stop:\n",
    "                    print('Early stopping')\n",
    "                    break\n",
    "                    \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best validation F1-score: {:.4f}'.format(best_f1))\n",
    "    \n",
    "    model.load_state_dict(torch.load('{}/checkpoint.pt').format(\n",
    "                        os.path.join(config['model_path'], config['model_name'])))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c5c2164b-d2f0-4e80-b8a0-3732460f5342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15120 3780\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 01/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ccfe15b7a7439bb9111a2c479e15d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 1.0173 | Acc: 0.7032 | F1-score: 0.5271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d6e9da4ecc432092216b40f84dc367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.3043 | Acc: 0.8921 | F1-score: 0.7785\n",
      "Validation f1-score increased (0.000000 --> 0.778511).  Saving model ...\n",
      "\n",
      "Epoch 02/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c5bb4cec534085b70062571d0ee007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.2915 | Acc: 0.8967 | F1-score: 0.7917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78280cfdb9fe46059b69231f6d7fec22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.1821 | Acc: 0.9302 | F1-score: 0.8486\n",
      "Validation f1-score increased (0.778511 --> 0.848558).  Saving model ...\n",
      "\n",
      "\n",
      "\n",
      "Epoch 03/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f96119242204a2a97e472d1341dc1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.1783 | Acc: 0.9370 | F1-score: 0.8694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7297825912e14a069b4019cb5ca76047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.1308 | Acc: 0.9519 | F1-score: 0.8905\n",
      "Validation f1-score increased (0.848558 --> 0.890470).  Saving model ...\n",
      "\n",
      "Epoch 04/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e91b8576423405e9cfa728e6ded1980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.1141 | Acc: 0.9607 | F1-score: 0.9199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b41b1cc07e4eb99f98c698be7dfef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0873 | Acc: 0.9667 | F1-score: 0.9170\n",
      "Validation f1-score increased (0.890470 --> 0.916981).  Saving model ...\n",
      "\n",
      "Epoch 05/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ac2357a20f49f198d684d70f72859d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train | Loss: 0.0725 | Acc: 0.9744 | F1-score: 0.9431\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56634fcc14d34dadae9ab54f56a8add8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0690 | Acc: 0.9746 | F1-score: 0.9224\n",
      "Validation f1-score increased (0.916981 --> 0.922417).  Saving model ...\n",
      "\n",
      "Epoch 06/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6883590d6854be198cedb2dea7d586f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.0506 | Acc: 0.9839 | F1-score: 0.9668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af669dc08a364550a2942ce2e9ec3ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0600 | Acc: 0.9786 | F1-score: 0.9425\n",
      "Validation f1-score increased (0.922417 --> 0.942462).  Saving model ...\n",
      "\n",
      "Epoch 07/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a302685ccdc4d9ca7af6070d1c31a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.0395 | Acc: 0.9876 | F1-score: 0.9727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72865eabd7f64ae397d4750c7f789532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0574 | Acc: 0.9794 | F1-score: 0.9437\n",
      "Validation f1-score increased (0.942462 --> 0.943663).  Saving model ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 08/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1d8ad55c034763b26f4f7773416565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.0384 | Acc: 0.9882 | F1-score: 0.9763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21c4f59e1ff415ebbd6ae09920993d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0535 | Acc: 0.9807 | F1-score: 0.9525\n",
      "Validation f1-score increased (0.943663 --> 0.952491).  Saving model ...\n",
      "\n",
      "Epoch 09/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76a1cfcbbd449c1b1ed72f56228077c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.0361 | Acc: 0.9892 | F1-score: 0.9762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887703b6766e47beb2a9b94c7fa3b2d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0528 | Acc: 0.9807 | F1-score: 0.9488\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\n",
      "Epoch 10/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5ebe942c6b4470acc2c33f3da4307b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train | Loss: 0.0346 | Acc: 0.9893 | F1-score: 0.9800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7558c75c55a45adb1118c799ab55fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0537 | Acc: 0.9810 | F1-score: 0.9532\n",
      "Validation f1-score increased (0.952491 --> 0.953247).  Saving model ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 11/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4673268d88734190a06942e918a73374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.0318 | Acc: 0.9898 | F1-score: 0.9776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dad2332a024b638ef9f99b084d549b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0520 | Acc: 0.9812 | F1-score: 0.9443\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\n",
      "Epoch 12/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3100a9ff0caf4c18b2cefd11371b31ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train | Loss: 0.0304 | Acc: 0.9905 | F1-score: 0.9798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d04f4350a76446f83d7f0e01c3101b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0518 | Acc: 0.9807 | F1-score: 0.9511\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\n",
      "Epoch 13/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f35e0a9ad4ef1b3e7e0a9bcfbfbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train | Loss: 0.0311 | Acc: 0.9914 | F1-score: 0.9831\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f58abecd244fd0a4392d2e5f04bd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0521 | Acc: 0.9810 | F1-score: 0.9545\n",
      "Validation f1-score increased (0.953247 --> 0.954478).  Saving model ...\n",
      "\n",
      "Epoch 14/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a13106d4564828b5d1cf066657e492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.0321 | Acc: 0.9903 | F1-score: 0.9787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554b624f9f084df0b482dc9d8ef22b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0505 | Acc: 0.9841 | F1-score: 0.9618\n",
      "Validation f1-score increased (0.954478 --> 0.961759).  Saving model ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 15/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2fb9915b314afa8102451ff93ca86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | Loss: 0.0315 | Acc: 0.9901 | F1-score: 0.9782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3649f6757284ff8ade9d2b43445362b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0507 | Acc: 0.9804 | F1-score: 0.9537\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\n",
      "Epoch 16/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc6ef6383f14e839117d8df1d8898d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train | Loss: 0.0299 | Acc: 0.9917 | F1-score: 0.9838\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f48a82ebd84495afd16eeb9a2a852a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0496 | Acc: 0.9820 | F1-score: 0.9578\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\n",
      "Epoch 17/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5aedf39076b4dbcb31cd7d04bda08da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train | Loss: 0.0313 | Acc: 0.9911 | F1-score: 0.9822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06982509df14e25bbafc2b5caae90c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0501 | Acc: 0.9825 | F1-score: 0.9548\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "\n",
      "Epoch 18/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a167a4892fac441d86d2ef0f792cb2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train | Loss: 0.0332 | Acc: 0.9902 | F1-score: 0.9795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab43cfa8f5540f1961cea9328a06833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0510 | Acc: 0.9802 | F1-score: 0.9475\n",
      "EarlyStopping counter: 4 out of 3\n",
      "Early stopping\n",
      "\n",
      "Epoch 19/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93685dbad6a40e29fb007fefe710dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train | Loss: 0.0276 | Acc: 0.9918 | F1-score: 0.9835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d593a67bf74bc99f356695e16b226f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0516 | Acc: 0.9820 | F1-score: 0.9552\n",
      "EarlyStopping counter: 5 out of 3\n",
      "Early stopping\n",
      "\n",
      "Epoch 20/20\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950a46ea8fec45f79efc41a6cd00e346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train | Loss: 0.0292 | Acc: 0.9912 | F1-score: 0.9832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4eb7d9b64e4bf0914a849ea48c01c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid | Loss: 0.0492 | Acc: 0.9823 | F1-score: 0.9554\n",
      "EarlyStopping counter: 6 out of 3\n",
      "Early stopping\n",
      "\n",
      "Training complete in 34m 50s\n",
      "Best validation F1-score: 0.9618\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '{}/checkpoint.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-110af894121a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-a2d13df47a5c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best validation F1-score: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     model.load_state_dict(torch.load('{}/checkpoint.pt').format(\n\u001b[0m\u001b[1;32m    131\u001b[0m                         os.path.join(config['model_path'], config['model_name'])))\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '{}/checkpoint.pt'"
     ]
    }
   ],
   "source": [
    "model = train_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c36a13-7c74-4780-8226-5ef76419edca",
   "metadata": {},
   "source": [
    "## 학습 그래프 표출 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-feelings",
   "metadata": {},
   "source": [
    "## Inference 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6ac2920-47d2-4ec4-b0c1-b5dba7621baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumission_dir 생성\n",
    "my_make_dir(cfg.submission_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d4130-6e04-4654-88e0-1fde6ef38d29",
   "metadata": {},
   "source": [
    "## 6.1 Test Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acffdc4d-4bd5-4244-baa6-d4c56e66320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = np.array(Image.open(self.img_paths[index]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)\n",
    "            image = image['image']\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f15360cb-8178-4969-bf1f-251550030ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/ml/code/model/efficientnet_b3_1/checkpoint.pt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(glob.glob(os.path.join(cfg.model_save_path, cfg.model_name) + '_*/checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e22051-734d-40ee-bbaa-9084ee0a7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = albumentations.Compose([\n",
    "    albumentations.CenterCrop(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE, p=1.0),\n",
    "    albumentations.Normalize(cfg.mean_list, cfg.std_list, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "coral-shade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28809ed914a74d608dee774624ff4581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=394.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 번째 sumission file 생성!\n",
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋 추론 메인 코드\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(cfg.test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(cfg.test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "dataset = TestDataset(image_paths, test_transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=cfg.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=cfg.NUM_WORKERS,\n",
    ")\n",
    "\n",
    "# KFOLD를 이용한 모델 5개의 checkpoint.pt path\n",
    "checkpoint_path_list = sorted(glob.glob(os.path.join(cfg.model_save_path, \n",
    "                                                     cfg.model_name) + '_*/checkpoint.pt'))\n",
    "for i, checkpoint_path in enumerate(checkpoint_path_list):\n",
    "    # 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "    model = ImgClassifier(model_name=cfg.model_name, \n",
    "                          n_class=cfg.CLASS_NUM, \n",
    "                          pretrained=False).to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    model.eval()\n",
    "\n",
    "    # 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "    all_predictions = []\n",
    "    for images in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            pred = model(images)\n",
    "            pred = pred.argmax(dim=-1)\n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "    submission['ans'] = all_predictions\n",
    "\n",
    "    # 제출할 파일을 저장합니다.\n",
    "    submission.to_csv(os.path.join(cfg.submission_dir, 'submission_{}.csv'.format(\n",
    "        checkpoint_path.split('/')[-2])), index=False)\n",
    "    \n",
    "    print(f'{i + 1} 번째 sumission file 생성!')\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d433962-df60-4245-9ff5-ebebfe6abdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_list = glob.glob(os.path.join(cfg.submission_dir, \n",
    "                                             'submission_{}_*'.format(cfg.model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14a76a4c-e213-4236-9c3d-879ae7898d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/ml/code/submission/2021-08-26/submission_tf_efficientnet_b4_ns_1 (78.143_0.729).csv',\n",
       " '/opt/ml/code/submission/2021-08-26/submission_tf_efficientnet_b4_ns_1.csv']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "444a782f-5f83-41fe-862b-03ed0b76c197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc74f19d250>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "result_df = pd.read_csv(submission_file_list[0])\n",
    "sns.countplot(result_df['ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5da54016-d632-4ee5-bcd4-b82a6754fa9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ans_2' 'ans_3' 'ans_4' 'ans_5'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c340df73f69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ans'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ans_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m result_df.to_csv(os.path.join(cfg.submission_dir, \n\u001b[1;32m     12\u001b[0m                               'submission_{}_ensemble.csv'.format(cfg.model_name)),\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4165\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4166\u001b[0m         \"\"\"\n\u001b[0;32m-> 4167\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4168\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4169\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ans_2' 'ans_3' 'ans_4' 'ans_5'] not found in axis\""
     ]
    }
   ],
   "source": [
    "for i, file in enumerate(submission_file_list):\n",
    "    if i == 0:\n",
    "        result_df = pd.read_csv(file)\n",
    "        result_df.rename({'ans': 'ans_1'}, axis=1, inplace=True)\n",
    "    else:\n",
    "        temp_df = pd.read_csv(file)\n",
    "        result_df['ans_{}'.format(i + 1)] = temp_df['ans']\n",
    "        \n",
    "result_df['ans'] = result_df.apply(lambda x: x.iloc[1:].value_counts().index[0], axis=1)\n",
    "result_df.drop(['ans_{}'.format(i) for i in range(1, 6)], axis=1, inplace=True)\n",
    "result_df.to_csv(os.path.join(cfg.submission_dir, \n",
    "                              'submission_{}_ensemble.csv'.format(cfg.model_name)),\n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96313eb-0fa4-4b87-955e-9fe7bfeb88df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
